{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "091ba2cb-fa3e-48bb-a6ad-4350861cd96e",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from pyspark import SparkConf\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# To adjust to our context\n",
    "NAMESPACE = \"spark-sapp-work\"\n",
    "HIVE_METASTORE_URI = \"thrift://hive-metastore.spark-sapp-sys.svc:9083\"\n",
    "SPARK_BUCKET = \"spark-sapp\"\n",
    "S3_ENDPOINT = \"https://n0.minio1:9000/\"\n",
    "S3_ACCESS_KEY = \"spark-sapp\"\n",
    "S3_SECRET_KEY = \"pd2t3yiizB0hTRjQOiIMihNNwMGeBM9P1vd1We2cUK1_MrAkRzY4qg==\"\n",
    "S3_SSL=\"true\"\n",
    "#  kubectl -n spark-sapp-work describe secret $(kubectl -n spark-sapp-work get secret | (grep spark || echo \"$_\") | awk '{print $1}') | grep token: | awk '{print $2}'\n",
    "OAUTH_TOKEN = \"eyJhbGciOiJSUzI1NiIsImtpZCI6Ik92a2tYVFhwbVNndUR0QnZDLTVsSkFIRk1sR0VuWWdJbE5qVXZNTUZlQkkifQ.eyJpc3MiOiJrdWJlcm5ldGVzL3NlcnZpY2VhY2NvdW50Iiwia3ViZXJuZXRlcy5pby9zZXJ2aWNlYWNjb3VudC9uYW1lc3BhY2UiOiJzcGFyay1zYXBwLXdvcmsiLCJrdWJlcm5ldGVzLmlvL3NlcnZpY2VhY2NvdW50L3NlY3JldC5uYW1lIjoic3BhcmstdG9rZW4tbWN2NHMiLCJrdWJlcm5ldGVzLmlvL3NlcnZpY2VhY2NvdW50L3NlcnZpY2UtYWNjb3VudC5uYW1lIjoic3BhcmsiLCJrdWJlcm5ldGVzLmlvL3NlcnZpY2VhY2NvdW50L3NlcnZpY2UtYWNjb3VudC51aWQiOiJhNzIwZDUwZC04MTk2LTQwZTEtOGZiYi0zNTJmYmRkODkyYTUiLCJzdWIiOiJzeXN0ZW06c2VydmljZWFjY291bnQ6c3Bhcmstc2FwcC13b3JrOnNwYXJrIn0.pwkhBXy7hOILG-KYG2ImER5-kJDlmwRkw0a04ACszWSYjBnOXoToTLdBo8v2GZYETzw1-2t1ja62qW1YvxEgOwSwnHQTeh87qi3mYhl1e37-OFj0X4YCrt41cMfBQUJaxo8uX-xV-98INB4GtdkgE2aSP1roNZj1ft-SwVC_tXx3GvWm4lhDGxQ7uuxtVzc2xEXZBffSsXUpm-fKzqatT3x3hQVRD4TNLF0DoU84LnbPyPz8ZcAt9zF4apJWBaHQJnVcoK-OnW4nnhQng6ffI-qKqKvwi89-Irfc5FrW5cl9nj3CWtos_W889VPk8UN_6M2DLHRtFec6L5SlU2fWQQ\"\n",
    "\n",
    "# Get Locol/driver ip address\n",
    "import socket\n",
    "hostname = socket.gethostname()\n",
    "driverIpAddress = socket.gethostbyname(hostname)\n",
    "\n",
    "config = {\n",
    "    \"spark.kubernetes.authenticate.oauthToken\": OAUTH_TOKEN,\n",
    "    \"spark.kubernetes.namespace\": NAMESPACE,\n",
    "    \"spark.hadoop.fs.s3a.endpoint\": S3_ENDPOINT,\n",
    "    \"spark.hadoop.fs.s3a.access.key\": S3_ACCESS_KEY,\n",
    "    \"spark.hadoop.fs.s3a.secret.key\": S3_SECRET_KEY,\n",
    "    \"spark.hadoop.fs.s3a.commection.ssl.enabled\": S3_SSL,\n",
    "    \"spark.eventLog.dir\": \"s3a://{}/eventlogs\".format(SPARK_BUCKET),\n",
    "    \"spark.hive.metastore.uris\": HIVE_METASTORE_URI,\n",
    "    \"spark.sql.warehouse.dir\": \"s3a://{}/warehouse\".format(SPARK_BUCKET),\n",
    "    \"hive.metastore.warehouse.dir\": \"s3a://{}/warehouse\".format(SPARK_BUCKET),\n",
    "\n",
    "    \"spark.executor.instances\": \"2\",\n",
    "    \"spark.kubernetes.executor.limit.cores\": \"1500m\",\n",
    "    \"spark.kubernetes.executor.request.cores\": \"500m\",\n",
    "    \"spark.executor.memory\": \"1g\",\n",
    "    \"spark.kubernetes.container.image\": \"ghcr.io/opendataplatform/spark-odp:3.2.1\",\n",
    "    \"spark.kubernetes.container.image.pullPolicy\": \"Always\",\n",
    "    \"spark.kubernetes.authenticate.executor.serviceAccountName\": \"spark\",\n",
    "    # Spark History Logs\n",
    "    \"spark.eventLog.enabled\": \"true\",\n",
    "    # Constant values\n",
    "    \"spark.hadoop.mapreduce.outputcommitter.factory.scheme.s3a\": \"org.apache.hadoop.fs.s3a.commit.S3ACommitterFactory\",\n",
    "    \"spark.hadoop.fs.s3a.committer.name\": \"directory\",\n",
    "    \"spark.hadoop.fs.s3a.committer.staging.tmp.path\": \"tmp/spark_staging\",\n",
    "    \"spark.hadoop.fs.s3a.buffer.dir\": \"/tmp/spark_local_buf\",\n",
    "    \"spark.hadoop.fs.s3a.committer.staging.conflict-mode\": \"fail\",\n",
    "    \"spark.hadoop.fs.s3a.impl\": \"org.apache.hadoop.fs.s3a.S3AFileSystem\",\n",
    "    \"spark.hadoop.fs.s3a.path.style.access\": \"true\",\n",
    "    \"spark.hadoop.fs.s3a.fast.upload\": \"true\",\n",
    "        \n",
    "    # \"spark.driver.blockManager.port\": \"7777\",\n",
    "    # \"spark.driver.port\": \"2222\",\n",
    "    \"spark.driver.host\": driverIpAddress,\n",
    "    \"spark.driver.bindAddress\": \"0.0.0.0\",\n",
    "\n",
    "    \"spark.sql.legacy.allowNonEmptyLocationInCTAS\": \"true\"\n",
    "}\n",
    "    \n",
    "def get_spark_session(app_name: str, conf: SparkConf):\n",
    "    conf.setMaster(\"k8s://https://kubernetes.default.svc\")\n",
    "    for key, value in config.items():\n",
    "        conf.set(key, value)    \n",
    "    return SparkSession.builder.appName(app_name).config(conf=conf).enableHiveSupport().getOrCreate()\n",
    "\n",
    "spark_conf= SparkConf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "56f8fbfd-4137-48f5-bd58-251213676710",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "spark = get_spark_session(\"ctemp-jup-py\", spark_conf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e7ff14d2-98b9-4f03-96ce-3e3ed4826948",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    " df = spark.read.options(header='True', inferSchema='True', delimiter=\",\").csv(\"s3a://spark-sapp/data/city_temperature.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b20977b9-4ec1-4c34-9dcc-39b30449ef86",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------+-----+-------+-----+---+----+--------------+\n",
      "|Region|Country|State|   City|Month|Day|Year|AvgTemperature|\n",
      "+------+-------+-----+-------+-----+---+----+--------------+\n",
      "|Africa|Algeria| null|Algiers|    1|  1|1995|          64.2|\n",
      "|Africa|Algeria| null|Algiers|    1|  2|1995|          49.4|\n",
      "|Africa|Algeria| null|Algiers|    1|  3|1995|          48.8|\n",
      "|Africa|Algeria| null|Algiers|    1|  4|1995|          46.4|\n",
      "|Africa|Algeria| null|Algiers|    1|  5|1995|          47.9|\n",
      "|Africa|Algeria| null|Algiers|    1|  6|1995|          48.7|\n",
      "|Africa|Algeria| null|Algiers|    1|  7|1995|          48.9|\n",
      "|Africa|Algeria| null|Algiers|    1|  8|1995|          49.1|\n",
      "|Africa|Algeria| null|Algiers|    1|  9|1995|          49.0|\n",
      "|Africa|Algeria| null|Algiers|    1| 10|1995|          51.9|\n",
      "|Africa|Algeria| null|Algiers|    1| 11|1995|          51.7|\n",
      "|Africa|Algeria| null|Algiers|    1| 12|1995|          51.3|\n",
      "|Africa|Algeria| null|Algiers|    1| 13|1995|          47.0|\n",
      "|Africa|Algeria| null|Algiers|    1| 14|1995|          46.9|\n",
      "|Africa|Algeria| null|Algiers|    1| 15|1995|          47.5|\n",
      "|Africa|Algeria| null|Algiers|    1| 16|1995|          45.9|\n",
      "|Africa|Algeria| null|Algiers|    1| 17|1995|          44.5|\n",
      "|Africa|Algeria| null|Algiers|    1| 18|1995|          50.7|\n",
      "|Africa|Algeria| null|Algiers|    1| 19|1995|          54.0|\n",
      "|Africa|Algeria| null|Algiers|    1| 20|1995|          52.6|\n",
      "+------+-------+-----+-------+-----+---+----+--------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b99d48f8-7798-41cf-b936-8d07085bd495",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df.createOrReplaceTempView(\"_src_\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e15e23e5-380a-4f22-b878-9ad86427655d",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"CREATE DATABASE IF NOT EXISTS sapp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1373f750-54d4-4c16-accb-2049279aba52",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " spark.sql(\"DROP TABLE IF EXISTS sapp.ctemp_jup_py\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "99024bbd-8261-41c1-94af-093f73f59802",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"CREATE TABLE IF NOT EXISTS sapp.ctemp_jup_py USING PARQUET LOCATION 's3a://spark-sapp//warehouse/sapp.db/ctemp_jup_py' AS SELECT * FROM _src_\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "0659a67d-eae0-4a7f-9211-dc8cf31d1c02",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+\n",
      "|namespace|\n",
      "+---------+\n",
      "|  default|\n",
      "|     sapp|\n",
      "+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"show databases;\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "0a11dd47-5e2f-4ab2-98a4-be9a5d0b4f81",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-------------------+-----------+\n",
      "|namespace|          tableName|isTemporary|\n",
      "+---------+-------------------+-----------+\n",
      "|     sapp| ctemp_airflow_java|      false|\n",
      "|     sapp|ctemp_airflow_java1|      false|\n",
      "|     sapp|ctemp_airflow_java2|      false|\n",
      "|     sapp|ctemp_airflow_java3|      false|\n",
      "|     sapp|   ctemp_airflow_py|      false|\n",
      "|     sapp|  ctemp_airflow_py1|      false|\n",
      "|     sapp|  ctemp_airflow_py2|      false|\n",
      "|     sapp|  ctemp_airflow_py3|      false|\n",
      "|     sapp|     ctemp_awf_java|      false|\n",
      "|     sapp|    ctemp_awf_java1|      false|\n",
      "|     sapp|    ctemp_awf_java2|      false|\n",
      "|     sapp|    ctemp_awf_java3|      false|\n",
      "|     sapp|       ctemp_awf_py|      false|\n",
      "|     sapp|      ctemp_awf_py1|      false|\n",
      "|     sapp|      ctemp_awf_py2|      false|\n",
      "|     sapp|      ctemp_awf_py3|      false|\n",
      "|     sapp|      ctemp_awf_py4|      false|\n",
      "|     sapp| ctemp_desktop_java|      false|\n",
      "|     sapp|   ctemp_desktop_py|      false|\n",
      "|     sapp|         ctemp_java|      false|\n",
      "+---------+-------------------+-----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"show tables from sapp;\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b86e3578-77e3-4723-8123-22770ca03b1d",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+---------+-------+\n",
      "|      col_name|data_type|comment|\n",
      "+--------------+---------+-------+\n",
      "|        Region|   string|   null|\n",
      "|       Country|   string|   null|\n",
      "|         State|   string|   null|\n",
      "|          City|   string|   null|\n",
      "|         Month|      int|   null|\n",
      "|           Day|      int|   null|\n",
      "|          Year|      int|   null|\n",
      "|AvgTemperature|   double|   null|\n",
      "+--------------+---------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"DESCRIBE TABLE sapp.ctemp_jup_py\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f0ad536f-f285-41ae-b345-1c3674d1bc0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+\n",
      "|count(1)|\n",
      "+--------+\n",
      "| 2906327|\n",
      "+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SELECT COUNT(*) FROM sapp.ctemp_jup_py\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e12f3079-6e51-4809-aed6-5872e8efe4f1",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+-------+------+---------+-----+---+----+--------------+\n",
      "|       Region|Country| State|     City|Month|Day|Year|AvgTemperature|\n",
      "+-------------+-------+------+---------+-----+---+----+--------------+\n",
      "|North America|     US|Alaska|Fairbanks|   12| 31|1999|         -50.0|\n",
      "|North America|     US|Alaska|Fairbanks|    2|  5|1999|         -49.1|\n",
      "|North America|     US|Alaska|Fairbanks|    1| 29|2012|         -47.7|\n",
      "|North America|     US|Alaska|Fairbanks|    1|  1|2000|         -46.9|\n",
      "|North America|     US|Alaska|Fairbanks|    1|  5|1997|         -46.2|\n",
      "|North America|     US|Alaska|Fairbanks|    2|  4|1999|         -45.9|\n",
      "|North America|     US|Alaska|Fairbanks|   12| 30|1999|         -45.8|\n",
      "|North America|     US|Alaska|Fairbanks|    1| 27|2006|         -45.8|\n",
      "|North America|     US|Alaska|Fairbanks|    1|  3|2000|         -45.6|\n",
      "|North America|     US|Alaska|Fairbanks|    1|  2|2000|         -44.7|\n",
      "|North America|     US|Alaska|Fairbanks|    1| 28|2012|         -44.3|\n",
      "|North America|     US|Alaska|Fairbanks|    1| 13|2000|         -44.3|\n",
      "|North America|     US|Alaska|Fairbanks|    2|  3|1999|         -44.1|\n",
      "|North America|     US|Alaska|Fairbanks|    1| 15|2012|         -43.8|\n",
      "|North America|     US|Alaska|Fairbanks|    1| 18|2017|         -43.7|\n",
      "|North America|     US|Alaska|Fairbanks|    1| 19|2017|         -43.5|\n",
      "|North America|     US|Alaska|Fairbanks|    1|  6|2009|         -43.4|\n",
      "|North America|     US|Alaska|Fairbanks|    1|  3|1997|         -43.3|\n",
      "|North America|     US|Alaska|Fairbanks|   12| 21|2012|         -43.0|\n",
      "|North America|     US|Alaska|Fairbanks|    1| 12|2005|         -43.0|\n",
      "+-------------+-------+------+---------+-----+---+----+--------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SELECT * FROM sapp.ctemp_jup_py WHERE AvgTemperature != -99 ORDER BY AvgTemperature ASC\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "f9abb3e1-4015-4bdc-9880-950da2cb2961",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e60343e3-e3ac-4147-8d84-8d7c64b627a2",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "319e3952-3831-400d-a72a-ad8bd462fadd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}